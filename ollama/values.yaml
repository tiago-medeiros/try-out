ollama:
  gpu:
    # -- Enable GPU integration
    enabled: true

    # -- GPU type: 'nvidia' or 'amd'
    type: 'nvidia'

    # -- Specify the number of GPU to 2
    number: 1

  # -- List of models to pull at container startup
  models:
    - llama2

ingress:
  enabled: true
  hosts:
    - host: ollama.badtux.io
      paths:
        - path: /
          pathType: Prefix
